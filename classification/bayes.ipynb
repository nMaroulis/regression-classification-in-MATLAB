{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "iris_dataset = './iris.data'\n",
    "pima_dataset = './pima-indians-diabetes.data'\n",
    "iris_df = pd.read_csv(iris_dataset, sep=',', header=None)\n",
    "pima_df = pd.read_csv(pima_dataset, sep=',', header=None)\n",
    "\n",
    "iris_df =  pd.DataFrame(iris_df)\n",
    "iris_df = iris_df.sample(frac=1) # suffle dataset\n",
    "pima_df =  pd.DataFrame(pima_df)\n",
    "pima_df = pima_df.sample(frac=1)\n",
    "\n",
    "\n",
    "iris_data = iris_df.values\n",
    "pima_data = pima_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetClassDict(train_dataset, features):\n",
    "    iris_class = {}\n",
    "    for i in range(len(train_dataset)):\n",
    "        vector = train_dataset[i]\n",
    "        if (vector[-1] not in iris_class):\n",
    "            iris_class[vector[-1]] = []\n",
    "        iris_class[vector[-1]].append(vector[0:features])\n",
    "    return iris_class\n",
    "\n",
    "def mean(values):\n",
    "    m = sum(values)/float(len(values))\n",
    "    return m\n",
    "\n",
    "def stdev(values):\n",
    "    m = mean(values)\n",
    "    stdev = math.sqrt( sum([pow(v-m,2) for v in values])/float(len(values)-1) )\n",
    "    return stdev\n",
    "\n",
    "def summarize(x):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*x)]\n",
    "    \n",
    "    return summaries\n",
    "\n",
    "def summarizeByClass(train_dataset):\n",
    "\n",
    "    summaries = {}\n",
    "    for key, value in train_dataset.items():\n",
    "        summaries[key] = summarize(value)\n",
    "    return summaries\n",
    "\n",
    "\n",
    "def gaussianProbability(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "def calculateClassProbabilities(summaries, test_row):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = test_row[i]\n",
    "            probabilities[classValue] *= gaussianProbability(x, mean, stdev)\n",
    "    return probabilities\n",
    "\n",
    "def predict(summaries, test_row):\n",
    "    probabilities = calculateClassProbabilities(summaries, test_row)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy for IRIS dataset with 1/3 split:  96.0 %\n",
      "Total Accuracy for PIMA dataset with 1/3 split:  71.09375 %\n",
      "Total Accuracy after for IRIS using 10-fold cross validation:  95.33333333333334 %\n",
      "Total Accuracy after for PIMA using 10-fold cross validation:  74.52380952380952 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 0.33 SPLIT TRAINING \"\"\"\n",
    "\n",
    "split_ratio = 0.333\n",
    "iris_features = np.size(iris_data,1) -1\n",
    "pima_features = np.size(pima_data,1) -1\n",
    "\n",
    "########   IRIS DATASET    ########\n",
    "\n",
    "split_val = int( len(iris_data) * split_ratio) +1\n",
    "iris_train = iris_data[0:2*split_val]\n",
    "iris_test = iris_data[2*split_val:3*split_val]\n",
    "\n",
    "iris_train_dict = datasetClassDict(iris_train, iris_features)\n",
    "summaries = summarizeByClass(iris_train_dict) # prepare model\n",
    "# summaries now has mean and standard deviation for each feature in each class\n",
    "\n",
    "predictions = []\n",
    "    \n",
    "for i in range(len(iris_test)):\n",
    "    result = predict(summaries, iris_test[i])\n",
    "    predictions.append(result)\n",
    "\n",
    "match = 0\n",
    "if(len(predictions) == len(iris_test)):\n",
    "    for i in range(len(iris_test) ):\n",
    "        if iris_test[i][-1] == predictions[i]:\n",
    "            match += 1\n",
    "\n",
    "accuracy = (match/float(len(iris_test))) * 100.0\n",
    "\n",
    "print('Total Accuracy for IRIS dataset with 1/3 split: ', accuracy,'%')\n",
    "\n",
    "########   PIMA DATASET    ########\n",
    "\n",
    "split_val = int( len(pima_data) * split_ratio) +1\n",
    "\n",
    "pima_train = pima_data[0:2*split_val]\n",
    "pima_test = pima_data[2*split_val:3*split_val]\n",
    "pima_train_dict = datasetClassDict(pima_train, pima_features)\n",
    "summaries = summarizeByClass(pima_train_dict) # prepare model\n",
    "predictions = [] \n",
    "for i in range(len(pima_test)):\n",
    "    result = predict(summaries, pima_test[i])\n",
    "    predictions.append(result)\n",
    "match = 0\n",
    "if(len(predictions) == len(pima_test)):\n",
    "    for i in range(len(pima_test) ):\n",
    "        if pima_test[i][-1] == predictions[i]:\n",
    "            match += 1\n",
    "accuracy = (match/float(len(pima_test))) * 100.0\n",
    "print('Total Accuracy for PIMA dataset with 1/3 split: ', accuracy,'%')\n",
    "\n",
    "\n",
    "\"\"\" 10 FOLD VALIDATION \"\"\"\n",
    "\n",
    "folds = 10\n",
    "fold_size = int(len(iris_data) / folds)\n",
    "\n",
    "# dataset_dict = datasetClassDict(iris_data)\n",
    "# total_summaries = summarizeByClass(dataset_dict)\n",
    "total_accuracy = []\n",
    "for i in range(folds):\n",
    "    val_from = fold_size*i\n",
    "    val_to = (i+1)*fold_size\n",
    "\n",
    "    validation_set = iris_data[val_from:val_to]\n",
    "    \n",
    "    train_set = np.delete(iris_data, np.s_[val_from:val_to], 0)\n",
    "    train_set_dict = datasetClassDict(train_set, iris_features)\n",
    "    summaries = summarizeByClass(train_set_dict)\n",
    "\n",
    "    predictions = []\n",
    "    for i in range(len(validation_set)):\n",
    "        result = predict(summaries, validation_set[i])\n",
    "        predictions.append(result)\n",
    "\n",
    "    match = 0\n",
    "    if(len(predictions) == len(validation_set)):\n",
    "        for i in range(len(validation_set) ):\n",
    "            if validation_set[i][-1] == predictions[i]:\n",
    "                match += 1\n",
    "\n",
    "    accuracy = (match/float(len(validation_set))) * 100.0\n",
    "    total_accuracy.append(accuracy)\n",
    "print('Total Accuracy after for IRIS using 10-fold cross validation: ', np.mean(total_accuracy),'%')\n",
    "\n",
    "\n",
    "########   PIMA DATASET    ########\n",
    "\n",
    "fold_size = int(len(pima_data) / folds) \n",
    "\n",
    "total_accuracy = []\n",
    "for i in range(folds):\n",
    "    val_from = fold_size*i\n",
    "    val_to = (i+1)*fold_size\n",
    "    \n",
    "    if i == 9:\n",
    "        val_to = (len(pima_data))\n",
    "    validation_set = pima_data[val_from:val_to]\n",
    "    \n",
    "    train_set = np.delete(pima_data, np.s_[val_from:val_to], 0)\n",
    "    train_set_dict = datasetClassDict(train_set, pima_features)\n",
    "    summaries = summarizeByClass(train_set_dict)\n",
    "\n",
    "    predictions = []\n",
    "    for i in range(len(validation_set)):\n",
    "        result = predict(summaries, validation_set[i])\n",
    "        predictions.append(result)\n",
    "\n",
    "    match = 0\n",
    "    if(len(predictions) == len(validation_set)):\n",
    "        for i in range(len(validation_set) ):\n",
    "            if validation_set[i][-1] == predictions[i]:\n",
    "                match += 1\n",
    "\n",
    "    accuracy = (match/float(len(validation_set))) * 100.0\n",
    "    total_accuracy.append(accuracy)\n",
    "print('Total Accuracy after for PIMA using 10-fold cross validation: ', np.mean(total_accuracy),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
